\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{graphicx}
\usepackage{array}
\usepackage{verbatim}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath,amsthm,amsfonts,amssymb,latexsym}
\usepackage{bbm}
\usepackage{setspace}
\usepackage{xparse}
\usepackage{epstopdf}
\usepackage{pgf}
\usepackage[colorlinks=true,citecolor=blue]{hyperref}
\usepackage[nameinlink,capitalise]{cleveref}

\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.14}
\usetikzlibrary{patterns}
\usetikzlibrary{calc}
\usetikzlibrary{angles}
\usetikzlibrary{quotes}
\usetikzlibrary{external}

\onehalfspacing
% \setlength{\parskip}{6pt}

\DeclareDocumentCommand\abs{s m} {\IfBooleanTF{#1}{\left|#2\right|}{\left|#2\right|}}
\DeclareDocumentCommand\cont{o m o} {C\IfNoValueF{#1}{^{#1}}(#2\IfNoValueF{#3}{;#3})}
\DeclareDocumentCommand\contc{o m o} {C_c\IfNoValueF{#1}{^{#1}}(#2\IfNoValueF{#3}{;#3})}
\DeclareDocumentCommand\sobolev{m m o} {H^{#1}(#2 \IfNoValueF{#3}{,#3})}
\DeclareDocumentCommand\lp{m m o} {L^{#1}\left(#2 \IfNoValueF{#3}{,#3}\right)}
\DeclareDocumentCommand\norm{s m o} {\IfBooleanTF{#1}{\|#2\|}{\left\|#2\right\|}\IfNoValueF{#3}{_{#3}}}
\DeclareDocumentCommand\seminorm{m o o} {\left|#1\right|\IfNoValueF{#2}{_{#2 \IfNoValueF{#3}{,#3}}}}
\DeclareDocumentCommand\ip{s m m o} {\IfBooleanTF{#1}{\langle #2,#3 \rangle}{\left\langle #2,#3 \right\rangle}\IfNoValueF{#4}{_{#4}}}
\DeclareDocumentCommand\dup{m m o} {\left\langle{#1,#2}\right\rangle\IfNoValueF{#3}{_{#3', #3}}}
\DeclareDocumentCommand\gaussian{O{0} O{I}} {g_{#1, #2}}
\DeclareDocumentCommand\littleo{s o m} {o\IfNoValueF{#2}{_{#2}}\IfBooleanTF{#1}{(#3)}{\left(#3\right)}}
\DeclareDocumentCommand\bigo{s o m} {\mathcal O\IfNoValueF{#2}{_{#2}}\IfBooleanTF{#1}{(#3)}{\left(#3\right)}}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\re}{Re}
\DeclareMathOperator*{\trace}{tr}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\sym}{sym}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\e}{e}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\offdiag}{offdiag}

\newcommand{\revision}[1]{\textcolor{blue}{#1}}
\renewcommand{\revision}[1]{#1}
\newcommand{\gab}[1]{\textcolor{darkgreen}{#1}}
\newcommand{\commut}[2]{[#1, #2]}
\newcommand{\correlation}[1]{\left< #1 \right>}
\newcommand{\dummy}{\,\cdot\,}
\newcommand{\expect}[0]{\mathbf{E}}
\newcommand{\var}[0]{\mathbf{V}}
\newcommand{\iip}[2]{\left(\!\left(#1, #2\right)\!\right)}
\newcommand{\nat}{\mathbf N}
\newcommand{\poly}{\mathbf P}
\newcommand{\real}{\mathbf R}
\newcommand{\integer}{\mathbf Z}
\newcommand{\torus}{\mathbf T}
\newcommand{\grad}{\boldsymbol \nabla}
\newcommand{\hess}{\nabla^2}
\newcommand{\vect}[1]{\boldsymbol{\mathbf #1}}
\newcommand{\mat}[1]{\vect #1}
\renewcommand{\det}[1]{\mathrm{det} \left( #1 \right)}
\renewcommand{\d}{\mathrm d}
\renewcommand{\t}{\mathsf T}
% \renewcommand{\t}{t}

\makeatletter
\DeclareDocumentCommand \derivative{s m o m}{%
    \def\@der{\IfBooleanTF{#1}{\mathrm{d}}{\partial}}
    \def\@default{%
        \mathchoice{%
                \frac{%
                    \@der\ifnum\pdfstrcmp{#2}{1}=0\else^{#2}\fi {\IfNoValueTF{#3}{}{#3}}
                }{%
                    \@for\@token:={#4}\do{\@der \@token}
                }
            } {%
                \@for\@token:={#4}\do{\@der_\@token} \IfNoValueTF{#3}{}{#3}
            } {} {}
    }
    \IfBooleanTF{#1}{\IfNoValueTF{#3}{\@default}{%
                #3%
                \ifnum\pdfstrcmp{#2}{1}=0'\else%
                \ifnum\pdfstrcmp{#2}{2}=0''\else%
                \ifnum\pdfstrcmp{#2}{3}=0^{(3)}\else%
                \ifnum\pdfstrcmp{#2}{4}=0^{(4)}\else%
                \ifnum\pdfstrcmp{#2}{5}=0^{(5)}\else%
                ^{(#2)}\fi\fi\fi\fi\fi
            }
        }{\@default}
}
\makeatother

\definecolor{darkred}{rgb}{.5,0,0}
\definecolor{darkgreen}{rgb}{0,.5,0}
\definecolor{darkblue}{rgb}{0,0,.5}
\newcommand{\red}[1]{\textcolor{darkred}{#1}}
\newcommand{\green}[1]{\textcolor{darkgreen}{#1}}

\theoremstyle{plain}
\newtheorem{assumption}{Assumption}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{result}{Result}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\numberwithin{equation}{section}

\newcounter{urbainCounter}
\newcommand{\urbain}[1]{\stepcounter{urbainCounter}\red{\arabic{urbainCounter}.} \green{#1}}
\crefname{equation}{}{}
\crefname{paragraph}{\S\!}{\S}
% \crefname{figure}{Figure}{Figures}
% \crefname{section}{Section}{Sections}

\newcommand{\email}[1]{\href{#1}{#1}}
\newcommand{\orcidcolor}{ORC\textcolor{orcidlogocol}{ID}}
\newcommand{\orcid}[1]{\href{https://orcid.org/#1}{\includegraphics[width=.4cm]{z_orcid.pdf}}}

%---------------- GABRIEL ------------
\usepackage{enumerate}
\newcommand{\eps}{\varepsilon}
\newcommand{\dps}{\displaystyle}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\ri}{\mathrm{i}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
% \usepackage{todonotes}
\usepackage{mathrsfs}

% BODY {{{1
\date{\today}
\title{Variance reduction for calculating the effective diffusion coefficient of Langevin dynamics}
\author{%
  % G.A. Pavliotis\thanks{Department of Mathematics, Imperial College London (\email{g.pavliotis@imperial.ac.uk})}%
  % \hspace{2mm}\orcid{0000-0002-3468-9227}%
  % \and G. Stoltz\thanks{CERMICS, \'Ecole des Ponts, France \& MATHERIALS, Inria Paris (\email{gabriel.stoltz@enpc.fr})}
  % \hspace{2mm}\orcid{0000-0002-2797-5938}%
  % \and U. Vaes\thanks{Department of Mathematics, Imperial College London (until October 2020) and MATHERIALS, Inria Paris (since November 2020) (\email{urbain.vaes@inria.fr})}%
  % \hspace{2mm}\orcid{0000-0002-7629-7184}%
}

\begin{document}
\maketitle

\section{Introduction}%
Let us first consider the Langevin dynamics in one dimension:
\begin{subequations}
\begin{align}
    \label{eq:Langevin_q}
    \d q &= p \, \d t, \\
    \label{eq:Langevin_p}
    \d p &= - \derivative*{1}[V]{q}(q) \, \d t - \gamma p \, \d t + \sqrt{2 \gamma \beta^{-1}} \d W_t.
\end{align}
\end{subequations}
The generator of the associated Markov semigroup is given by
\[
    \mathcal L = p \derivative{1}{q} - \derivative*{1}[V]{q}(q) \derivative{1}{p} + \gamma \left( - p \derivative{1}{p} + \beta^{-1} \derivative{2}{p^2} \right).
\]
Let $\phi$ denote the solution to
\[
    - \mathcal L \phi = p,
\]
and suppose that $\psi$ denote an approximation of $\phi$.
By It\^o's formula, it holds
\begin{align*}
    \phi(q_t, p_t) - \phi(q_0, p_0) &= - \int_{0}^{t} p_s \, \d s + \sqrt{2 \gamma \beta^{-1}} \int_{0}^{t} \derivative{1}[\phi]{p}(q_s, p_s) \, \d W_s \\
    \psi(q_t, p_t) - \psi(q_0, p_0) &= \int_{0}^{t} (\mathcal L \psi) (q_s, p_s) \, \d s + \sqrt{2 \gamma \beta^{-1}} \int_{0}^{t} \derivative{1}[\psi]{p}(q_s, p_s) \, \d W_s.
\end{align*}
Let also $u(t)$ and $v(t)$ denote the random variables
\[
    u(t) = \frac{\abs{q_t - q_0}^2}{2t}
\]
and
\begin{align*}
    v(t) &= D_{\psi}+ \frac{1}{2t} \left( \abs{q_t - q_0}^2 - \abs{\xi_t}^2\right)
\end{align*}
where $D_{\psi} := \gamma \beta^{-1} \int_{\torus \times \real} \abs{\derivative{1}[\psi]{p}}^2 \, \d \mu$ and
 \[
    \xi_t = \psi(q_t, p_t) - \psi(q_0, p_0) - \sqrt{2 \gamma \beta^{-1}} \int_{0}^{t} \derivative{1}[\psi]{p}(q_s, p_s) \, \d W_s
 \]
It holds
\[
    \lim_{t \to \infty} \expect \bigl( u(t) \bigr) = \lim_{t \to \infty} \expect \bigl( v(t) \bigr)
    = \gamma \beta^{-1} \int_{\torus \times \real} \abs{\derivative{1}[\phi]{p}}^2 \, \d \mu
    = \int_{\torus \times \real} \phi \, p \, \d \mu =: D_{\phi}.
\]
so both $u(t)$ and $v(t)$ are asymptotically unbiased estimators of $D_{\phi}$.

\paragraph{Bias of the estimator.}%

\begin{proposition}
    [Bias of the estimator]
    Assume stationary initial conditions $(q_0, p_0) \sim \mu$.
    Then
    \begin{align*}
        \forall t > 0, \quad \gamma > 0, \qquad
        \abs{\expect \bigl( v(t) \bigr) - D_{\phi}}
        \leq \frac{c_1}{c_2^2 t} \, \max(\gamma^2, \gamma^{-2}) \norm{\mathcal L\psi + p}  \left(1 + \norm{\mathcal L \psi} \right).
    \end{align*}
\end{proposition}
\begin{proof}
    For an observable $\zeta = \zeta(q, p)$ in $\lp{2}{\mu} \cap \mathcal D(\mathcal L)$,
    we denote $C_{\zeta}(s) := \ip{\mathcal L \zeta}{\e^{s \mathcal L} \mathcal L \zeta}$.
    With this notation, $C_{\phi}$ is the autocorrelation function of the momentum function $(q, p) \mapsto p$.
    It is well known~\cite{roussel2018spectral} that $\norm*{ \e^{s \mathcal L} }[\mathcal B \left(L^2_0\left(\mu\right) \right)] \leq M \exp \bigl(- \hat \lambda s \min(\gamma, \gamma^{-1}) \bigr)$
    for appropriate constants $M > 0$ and $\hat \lambda > 0$,
    so we obtain, using It\^o's isometry,
    \begin{align*}
        \expect \bigl(v(t)\bigr) - D_{\phi}
        &= D_{\psi} + \int_{0}^{t} \left(1 - \frac{s}{t}\right) \bigl( C_{\phi}(s) - C_{\psi}(s) \bigr) \, \d s. \\
        &= D_{\phi} - \int_{0}^{\infty} \min\left(1, \frac{s}{t}\right) \bigl( C_{\phi}(s) - C_{\psi}(s) \bigr) \, \d s,
    \end{align*}

    \begin{align*}
        \expect \bigl(u(t)\bigr)
        &= \frac{1}{2t} \expect \left( \int_{0}^{t} p_s \, \d s \int_{0}^{t} p_u \, \d u \right)
        = \frac{1}{2t} \left( \int_{0}^{t} \int_{0}^{t} \expect (p_s p_u) \, \d s \, \d u \right) \\
        &= \frac{1}{2t} \left( \int_{0}^{t} \int_{0}^{t} C_{\phi}(\abs{s - u}) \, \d s \, \d u \right)
        =  \int_{0}^{t} C_{\phi}(s) \left(1 - \frac{s}{t}\right) \d s  \\
        &= D_{\phi} - \int_{0}^{\infty} \min\left(1, \frac{s}{t}\right) C_{\phi}(s) \, \d s.
    \end{align*}
Since $\abs{C_{\phi}(s)} = \abs{\ip{p}{\e^{s \mathcal L} p}} \leq \norm{p} \, \norm{\e^{s \mathcal L} p} \leq \beta^{-1} c_1 \exp\bigl( - c_2 \min(\gamma, \gamma^{-1}) t\bigr)$, it holds
\[
    \forall t > 0, \quad \gamma > 0, \qquad
    \abs{\expect\bigl(u(t)\bigr) - D_{\phi}}
    \leq \frac{1}{t}\int_{0}^{\infty} s C_{\phi}(s) \, \d s
    \leq \frac{c_1}{c_2^2 t} \, \max\bigl(\gamma^{-2}, \gamma^2\bigr).
\]
It is well known that $D_{\phi} = \mathcal O(\gamma^{-1})$ in both the limit $\gamma \to 0$ and the limit $\gamma \to \infty$.
Therefore, the relative bias scales as $\max(\gamma^{-1}, \gamma^3) / t$.
Applying the same reasoning to $v(t)$, we obtain
\begin{align*}
    \expect \bigl(v(t)\bigr)
    &= D_{\psi} + \int_{0}^{t} \left(1 - \frac{s}{t}\right) \bigl( C_{\phi}(s) - C_{\psi}(s) \bigr) \, \d s. \\
    &= D_{\phi} - \int_{0}^{\infty} \min\left(1, \frac{s}{t}\right) \bigl( C_{\phi}(s) - C_{\psi}(s) \bigr) \, \d s,
\end{align*}
where $C_{\psi}(s) = \ip{\mathcal L \psi}{\e^{s \mathcal L} \mathcal L \psi}$.
We have
\begin{align*}
    C_{\phi}(s) - C_{\psi}(s)
    &= \ip{\mathcal L (\phi - \psi)}{\e^{s \mathcal L} \mathcal L \phi + \e^{s \mathcal L^*} \mathcal  L\psi} \\
    &\leq \norm{\mathcal L(\phi - \psi)}
    \left( \norm*{\e^{s \mathcal L}}[\mathcal B\left(L^2_0(\mu) \right)] \norm{\mathcal L \phi} + \norm*{\e^{s \mathcal L^*}}[\mathcal B\left(L^2_0(\mu) \right)] \norm{\mathcal L \psi} \right) \\
    &\leq c_1 \e^{-c_2 \min(\gamma, \gamma^{-1}) s} \norm{\mathcal L\psi + p}  \left(1 + \norm{\mathcal L \psi} \right),
\end{align*}
which concludes the proof.
\end{proof}

\begin{example}
    [Case of a quadratic potential]
    Consider the case of the quadratic confining potential $V(q) = \frac{k q^2}{2}$.
    In this case, the eigenfunctions of $\mathcal L$ are polynomials,
    with the linear ones and associated eigenvalues being
    \[
        v_{\pm}(q, p) =
        \left( \frac{\gamma \pm \sqrt{\gamma^2 - 4k}}{2} \right) q + p, \\
        \qquad
        \lambda_{\pm} = \frac{- \gamma \pm \sqrt{\gamma^2 - 4k}}{2}.
    \]
    The function $(q, p) \mapsto p$ is the following linear combination of these eigenfunctions:
    \[
        p =
        \left( \frac{-\gamma + \sqrt{\gamma^2 - 4k}}{2 \sqrt{\gamma^2 - 4k}} \right) v_+
        + \left( \frac{\gamma + \sqrt{\gamma^2 - 4k}}{2 \sqrt{\gamma^2 - 4k}} \right) v_-.
    \]
    Therefore, given that $\ip{v_+}{p} = \ip{v_-}{p} = \beta^{-1}$,
    the velocity autocorrelation function is
    \[
        \ip{\e^{t \mathcal L}p}{p} =
        \left( \frac{-\gamma + \sqrt{\gamma^2 - 4k}}{2 \beta \sqrt{\gamma^2 - 4k}} \right) \e^{\lambda_+ t} +
        \left( \frac{\gamma + \sqrt{\gamma^2 - 4k}}{2 \beta \sqrt{\gamma^2 - 4k}} \right) \e^{\lambda_- t} = T_1(t) + T_2(t).
    \]
    Although $\lambda_+ = \bigo {\gamma^{-1}}$ as $\gamma \to \infty$,
    it holds that $\int_{0}^{\infty} T_1(t) \, \d t = \bigo{\gamma^{-1}}$
    because the factor multiplying the exponential scales as $\bigo {\gamma^{-2}}$.
\end{example}


which leads to
\begin{align*}
    \forall t > 0, \quad \gamma > 0, \qquad
    \abs{\expect \left( v(t) \right) - D_{\phi}}
    \leq \frac{c_1}{c_2^2 t} \, \max(\gamma^2, \gamma^{-2}) \norm{\mathcal L\psi + p}  \left(1 + \norm{\mathcal L \psi} \right).
\end{align*}
The constant on the right-hand side is smaller when $\psi \approx \phi$,
and when $\psi = 0$ we recover the previous bound.

\begin{example}
    Consider the case where $V(q) = 0$.
    In this case, the solution to the Poisson equation $- \mathcal L \phi = p$ is given by $\phi(q, p) = \gamma^{-1} p$ and,
    applying Itô's formula to this function, we obtain
    (note that this equation can be derived directly from~\eqref{eq:Langevin_p})
    \[
        \gamma^{-1}(p_t - p_0) = - \int_{0}^{t} p_s \, \d s + \sqrt{2 \gamma^{-1} \beta^{-1}} (W_t - W_0)
        = q_0 - q_t + \sqrt{2 \gamma^{-1} \beta^{-1}} W_t.
    \]
    We deduce, using the explicit solution to the Ornstein--Uhlenbeck equation satisfied by $p$, that
    \begin{align*}
        q_t - q_0
        &= - \gamma^{-1} \left( p_0 \left(\e^{-\gamma t} - 1\right) + \sqrt{2 \gamma \beta^{-1}}\int_{0}^{t} \e^{-\gamma (t - s)} \, \d W_s \right)
        + \sqrt{2 \gamma^{-1} \beta^{-1}} W_t \\
        &=  - \gamma^{-1} p_0 \left(\e^{-\gamma t} - 1\right) + \sqrt{2 \gamma^{-1} \beta^{-1}}\int_{0}^{t} \left(1 - \e^{-\gamma (t - s)}\right) \, \d W_s.
    \end{align*}
    Assuming $p_0 \sim \mathcal N(0, \beta^{-1})$,
    the right-hand side of this equation is a mean-zero Gaussian random variable and,
    using It\^o's isometry, we calculate that
    \[
        \frac{\expect \abs{q_t - q_0}^2}{2t} = \gamma^{-1} \beta^{-1} \left( 1 + \frac{1}{t \gamma} \left(\e^{-\gamma t} - 1\right) \right)
    \]
\end{example}

\paragraph{Variance of the estimator.}%
For the variance, we can obtain a crude bound using
\begin{align*}
    \mathrm{Var} (v(t))
    &\leq \expect \left( \abs{v(t) - D_{\psi}}^2 \right)
    = \frac{1}{4 t^2} \expect \big( |q_t - q_0 - \xi_t|^2 |q_t - q_0 + \xi_t|^2 \big) \\
    &\leq \frac{1}{4 t^2} \sqrt{\expect \left(  |q_t - q_0 - \xi_t|^4 \right)} \sqrt{\expect \left( |q_t - q_0 + \xi_t|^4 \right)}.
\end{align*}
We now bound
\begin{align*}
    \expect \left( |q_t - q_0 + \xi_t|^4 \right)
    &= \expect \left( \abs{\phi_t - \phi_0 - \psi_t + \psi_0 + I_{\psi} - I_{\phi}}^4 \right) \\
    &\leq 3^3 \left( \expect \left( \abs{\phi_t - \psi_t}^4 \right) + \expect \left( \abs{\phi_0 - \psi_0}^4 \right) + \expect \left( \abs{I_{\psi} - I_{\phi}}^4 \right) \right).
\end{align*}
The first two terms are bounded by $\norm{\phi - \psi}_{L^4(\mu)}^4$.
Using a moment inequality for It\^o integrals, the last term can be bounded as
\[
    \expect \left( \abs{I_{\psi} - I_{\phi}}^4 \right) \leq 6 t \expect \int_{0}^{t} \abs{\derivative{1}[\phi]{p}(q_s, p_s) - \derivative{1}[\psi]{p}(q_s, p_s)}^4 \, \d s = 6 t \int \abs{\derivative{1}[\phi]{p} - \derivative{1}[\psi]{p}}^4 \d \mu.
\]
Likewise, the other term can be bounded as
\begin{align*}
    \expect \left( |q_t - q_0 - \xi_t|^4 \right)
    &\leq 3^3 \left( \expect \left( 2 \norm{\phi + \psi}[L^4(\mu)]^4 + 6 t \norm{\derivative{1}[\phi]{p} + \derivative{1}[\psi]{p}}[L^{4}(\mu)]^4 \right) \right).
\end{align*}

% \paragraph{Estimator diffusion coefficient.}%
% \label{par:estimator_diffusion_coefficient}

% Let $U_t = \sqrt{2 D} W_t$ and consider the estimator
% \[
%     2 \hat D = \frac{t_1 U_{t_1}^2 + \dotsb + t_N U_{t_N}^2}{t_1^2 + \dotsb + t_N^2},
% \]
% where $t_i = i \Delta_t$.
% This estimator is clearly unbiased: $\expect (\hat D) = D$.
% Let $\xi_i = (U_{t_{i}} - U_{t_{i-1}})/\sqrt{2D \Delta t}$, for $i = 1, \dotsc, N$.
% It holds
% \begin{align*}
%     \frac{\hat D - D}{D}
%     &= 6 \left( \frac{ \sum_{i=1}^{N} \sum_{j=i}^{N} (\xi_i ^2 - 1)  j  + 2 \sum_{i=1}^{N} \sum_{j=i+1}^{N} \sum_{k=i}^{j} \xi_i \xi_j k}
%     {1 + \dotsb + N^2} \right) \\
%     &= 3 \left( \frac{ \sum_{i=1}^{N} (\xi_i ^2 - 1)  (N+1-i)(N+i)  + 2 \sum_{i=1}^{N} \sum_{j=i+1}^{N} \xi_i \xi_j (j+1-i)(j+i)}
%     { N(N+1)(2N+1)} \right).
% \end{align*}
% We calculate
% \begin{align*}
%     \expect \abs{ \frac{\hat D - D}{D} }^2
%     &= 9 \left( \frac{ \sum_{i=1}^{N} \expect (\xi_i ^4 + 1 - 2 \xi_i^2)  (N+1-i)^2 (N+i)^2}
%     { N^2 (N+1)^2 (2N+1)^2} \right) \\
%     &\quad + 36 \left(  \frac{\sum_{i=1}^{N} \sum_{j=i+1}^{N} \expect \left( \abs{\xi_i}^2 \abs{\xi_j}^2 \right) \abs{j+1-i}^2 \abs{j+i}^2}
%     { N^2 (N+1)^2 (2N+1)^2} \right) \\
%     &= 18 \left( \frac{ \sum_{i=1}^{N}  (N+1-i)^2 (N+i)^2}
%     { N^2 (N+1)^2 (2N+1)^2} \right)
%     + 36 \left(  \frac{\sum_{i=1}^{N} \sum_{j=i+1}^{N} \abs{j+1-i}^2 \abs{j+i}^2}
%     { N^2 (N+1)^2 (2N+1)^2} \right).
% \end{align*}
\appendix
\section{Auxiliary technical results}%
\label{sec:auxiliary_technical_results}

\begin{lemma}
    Let $f(q, p) = Q(q) P(p)$ with $P \in L^2_0(\e^{-V})$.
    Then there exist constants $C$ and $\lambda$ such that
    \[
        \forall t \geq 0, \qquad
        \ip{\e^{t \mathcal L}f}{f} \leq C \left( \gamma^{-2} t \e^{- \frac{t}{\gamma}} + \e^{-\gamma t} \right).
    \]
\end{lemma}
\begin{proof}
    We consider the following decomposition of the generator:
    \[
        \mathcal L
        = \left( p \derivative{1}{q} - \derivative*{1}[V]{q}(q) \derivative{1}{p} \right)
        + \gamma \left( - p \derivative{1}{p} + \beta^{-1} \derivative{2}{p^2} \right)
        =: \mathcal L_{\rm ham} + \gamma \mathcal L_{\rm FD}.
    \]
    Let $v(t) = \e^{t \mathcal L} f(q, p) - Q(q) \e^{- t \gamma \mathcal L_{\rm FD}} P(p)$.
    The function $v$ satisfies the equation
    \[
        \partial_t v = \mathcal L v +  \mathcal L_{\rm ham} (Q(q) \e^{- t \gamma \mathcal L_{\rm FD}} P(p)), \qquad v(0) = 0.
    \]
    Using Duhamel's formula, we have
    \[
        v(t) = \int_{0}^{t} \e^{- (t-s) \mathcal L}  \Bigl( \mathcal L_{\rm ham} \bigl(Q(q) \e^{- t \gamma \mathcal L_{\rm FD}} P(p)\bigr) \Bigr) \, \d s,
    \]
    and therefore
    \begin{equation}
        \label{eq:intermediate_decay_correlation}
        \e^{t \mathcal L} f(q,p) = Q(q) \e^{- t \gamma \mathcal L_{\rm FD}} P(p) + \int_{0}^{t} \e^{- (t-s) \mathcal L}  \Bigl( \mathcal L_{\rm ham} \bigl(Q(q) \e^{- t \gamma \mathcal L_{\rm FD}} P(p)\bigr) \Bigr) \, \d s.
    \end{equation}
    For $t$ fixed, the function $(q, p) \mapsto \mathcal L_{\rm ham} \bigl(Q(q) \e^{- t \gamma \mathcal L_{\rm FD}} P(p)\bigr)$ is of the form $Q_1(q) P_1(p)+ Q_2(q) P_2(p)$.

    By \cref{lemma:backward_kolmogorov_obs_q},
    we have
    \[
        \e^{- (t-s) \mathcal L} \bigl(V'(q)\bigr)
        = \e^{- (t-s) \frac{1}{\gamma}\mathcal L_{\rm ov}} V' + R(t),
        % \leq C \e^{- \frac{\lambda}{\gamma} (t-s)} + \frac{C}{\gamma},
    \]
    where the remainder term is bounded as $\norm{R(t)} \leq \frac{C}{\gamma}$.
    Taking the inner product with $p$,
    and noting that the constant-in-$p$ part of the integrand vanishes,
    we obtain
    \[
        \ip{v(t)}{p} = \int_{0}^{t} R(s) \e^{-\gamma s} \, \d s
        \leq \frac{C}{\gamma^2}.
    \]
    so we deduce
    \[
        \norm{v(t)} \leq \int_{0}^{t} \e^{- \frac{\lambda}{\gamma}(t-s)} \e^{- \gamma s} \, \d s + \frac{C}{\gamma^2}.
    \]
\end{proof}

% \begin{proof}
%     Let $u(t) = \e^{t \mathcal L} p$ and $v(t) = u(t) - p \e^{-\gamma t}$.
%     The function $v$ satisfies the equation
%     \[
%         \partial_t v = \mathcal L v + V'(q) \, \e^{-\gamma t}, \qquad v(0) = 0.
%     \]
%     Using Duhamel's formula, we have
%     \[
%         v(t) = \int_{0}^{t} \e^{- (t-s) \mathcal L} \bigl(V'(q)\bigr) \e^{-\gamma s} \, \d s
%     \]
%     By \cref{lemma:backward_kolmogorov_obs_q},
%     we have
%     \[
%         \e^{- (t-s) \mathcal L} \bigl(V'(q)\bigr)
%         = \e^{- (t-s) \frac{1}{\gamma}\mathcal L_{\rm ov}} V' + R(t),
%         % \leq C \e^{- \frac{\lambda}{\gamma} (t-s)} + \frac{C}{\gamma},
%     \]
%     where the remainder term is bounded as $\norm{R(t)} \leq \frac{C}{\gamma}$.
%     Taking the inner product with $p$,
%     and noting that the constant-in-$p$ part of the integrand vanishes,
%     we obtain
%     \[
%         \ip{v(t)}{p} = \int_{0}^{t} R(s) \e^{-\gamma s} \, \d s
%         \leq \frac{C}{\gamma^2}.
%     \]
%     so we deduce
%     \[
%         \norm{v(t)} \leq \int_{0}^{t} \e^{- \frac{\lambda}{\gamma}(t-s)} \e^{- \gamma s} \, \d s + \frac{C}{\gamma^2}.
%     \]
% \end{proof}

\begin{lemma}
    \label{lemma:backward_kolmogorov_obs_q}
    Let $\mathcal L_{\rm ov} = - V'(q) \partial_q + \beta^{-1} \partial_q^2$ and $f \in L^2_0(\e^{-V}) \cap C^{\infty}(\torus)$.
    Let also $\bar f(q, p) = f(q)$ and
    \[
        \widehat u(t) = \e^{t\mathcal L_{\rm ov}} f, \qquad
        u(t) = \e^{t \gamma\mathcal L} \bar f.
    \]
    Then there exists $C > 0$ such that
    \[
        \forall \gamma \geq 1, \qquad
        \sup_{t \geq \!\!0}
        \norm{u(t)  - \widehat u(t)} \leq \frac{C}{\gamma}.
    \]
\end{lemma}
\begin{proof}
    Throughout this proof, $C$ denotes a positive constant that can change from occurrence to occurrence but is independent of $\gamma$.
    We recall that there exists a positive constants $\lambda_{\rm Lang}$ such that~\cite{roussel2018spectral,pavliotis2011applied}
    \begin{equation}
        \label{eq:decay_langevin}
        \forall \gamma > 0, \qquad
        \norm{\e^{t \gamma \mathcal L_{\rm Lang}}}[L^2_0(\mu)] \leq C \e^{- \lambda_{\rm Lang} \min\{1,\gamma^2\} t}.
    \end{equation}
    In addition, \cref{lemma:overdamped_langevin_decay_derivatives} implies the existence of $\lambda_{\rm ovd} > 0$ independent of $i$ such that
    \begin{equation}
        \label{eq:decay_ovd}
        \norm{\e^{t \mathcal L_{\rm ovd}}}[H^i(\mu) \cap L^2(\mu)] \leq C \e^{- \lambda_{\rm ovd} t}.
    \end{equation}
    Let $\widetilde u(q, p, t) = \widehat u(q, t) + \gamma^{-1} p \, \partial_q \widehat u(q, t) + \gamma^{-2} (\beta^{-1} - p^2) \partial_q^{2} \widehat u$.
    An explicit calculation gives
    \begin{align*}
        (\partial_t - \gamma \mathcal L) \widetilde u
        &= \gamma^{-1} p \, \partial_t \partial_q \widehat u(q, t) + \gamma^{-2} (\beta^{-1} - p^2) \partial_t \partial_q^{2} \widehat u
        + \gamma^{-1} p (\beta^{-1} - p^2) \partial_q^{3} \widehat u + 2 \gamma^{-1} p \, V'(q) \, \partial_q^2 \widehat u.
        % &=
    \end{align*}
    The right-hand side, which we denote by $\gamma^{-1} r(t)$, has values in $L^2_0(\mu)$,
    and the $L^2(\mu)$ norm of $r(t)$ is bounded uniformly in time by $C \e^{-\lambda_{\rm ovd} t}$ by \eqref{eq:decay_ovd}.
    Using the notation $e(t) = u(t) - \widetilde u(t)$,
    we deduce that $e$ satisfies the equation
    \[
        \partial_t e = \gamma \mathcal L e - \gamma^{-1} r, \qquad
        e(0) = \gamma^{-1} p \, f'(q) + \gamma^{-2} (\beta^{-1} - p^2) f''(q).
    \]
    By Duhamel's formula,
    this implies
    \[
        e(t) = \e^{t \gamma \mathcal L} \bigl( e(0) \bigr) + \gamma^{-1} \int_{0}^{t} \e^{(t- s) \gamma \mathcal L} r(s) \, \d s.
    \]
    From~\eqref{eq:decay_langevin} we deduce immediately that
    \begin{align*}
        e(t)
        &\leq C \e^{- \lambda_{\rm Lang} t} \norm{e(0)}
        + \gamma^{-1} \int_{0}^{t} C_1 C_2 \e^{- \lambda_{\rm Lang} (t-s)} \e^{-\lambda_{\rm ovd} s} \d s \\
        &\leq C \e^{- \lambda t} \norm{e(0)} + \gamma^{-1} C t \e^{- \lambda t},
    \end{align*}
    for $\lambda = \min(\lambda_{\rm ovd}, \lambda_{\rm Lang})$.
    The result then follows by noticing that
    \[
        \norm{\widetilde u(t) - \widehat u(t)} \leq C \gamma^{-1} \e^{- \lambda_{\rm ovd} t},
    \]
    by \cref{lemma:overdamped_langevin_decay_derivatives}.
\end{proof}

The following result shows the exponential convergence of the derivatives of the overdamped Langevin semigroup.
In order to state the result, we define the weighted Sobolev space $H^i(\mu)$ as the subspace of $L^2(\mu)$
of functions whose derivatives up to order $i$ are in $L^2(\mu)$.
The associated norm is given by
\[
    \norm{u}_i^2 = \norm{f}^2 + \norm*{f'}} + \dotsb + \norm*{f^{(i)}}.
\]

\begin{lemma}
    \label{lemma:overdamped_langevin_decay_derivatives}
    Assume that $f \in L^2_0(\e^{-V}) \cap C^{\infty}(\torus)$,
    and let $u(t) = \e^{t \mathcal L_{\rm ovd}} f$.
    For any $\lambda \in (0, 1)$ and every $i \geq 0$,
    there exists $K = K(\lambda, i)$ such that
    \[
        \norm*{u(t)}_i^2 \leq K \e^{- 2 R t} \norm*{u(0)}_i^2,
    \]
    where $R$ is the constant in the Poincaré inequality associated with $\e^{-V}$,
    that is
    \[
        \forall f \in H^1(\mu) \cap L^2_0(\mu), \qquad
        \norm*{f}^2 \leq \frac{1}{2R} \norm{\partial_q f}^2.
    \]
\end{lemma}
\begin{proof}
    Let $i \geq 0$ and $\seminorm{u}_i = \norm*{(- \mathcal L_{\rm ovd})^{i/2} u}$.
    Since $\mathcal L_{\rm ovd}$ commutes with $(-\mathcal L_{\rm ovd})^{i/2}$,
    it holds that
    \[
        \frac{1}{2} \derivative*{1}{t} \seminorm{u}_i^2 = \ip{\mathcal L_{\rm ovd} (-\mathcal L_{\rm ovd})^{i/2} u}{(- \mathcal L_{\rm ovd})^{i/2} u}.
    \]
    Introducing $\partial_q^* = \beta V' - \partial_q$
    and noting that $\mathcal L_{\rm ovd} = - \partial_q^* \partial_q$,
    we obtain
    \[
        \frac{1}{2} \derivative*{1}{t} \seminorm{u}_i^2 = - \norm*{\partial_q (-\mathcal L_{\rm ovd})^{i/2} u}.
    \]
    Since $(-\mathcal L_{\rm ovd})^{i/2} u \in L^2_0(\mu)$,
    we can apply Poincar\'e's inequality, which gives
    \[
        \frac{1}{2} \derivative*{1}{t} \seminorm{u}_i^2 \leq - 2R \seminorm{u}_i^2,
    \]
    implying the exponential convergence estimate
    \begin{equation}
        \label{eq:exponential_convergence}
        \forall t \geq 0, \qquad
        \seminorm{u(t)}_i \leq \e^{- 2 R t} \seminorm{u(0)}_i.
    \end{equation}
    Applying this estimate with $i = 0$ gives the usual convergence estimate for the norm $\norm{u}$.
    For~$i = 1$, it holds for sufficiently regular $h$ that
    \[
        \seminorm{h}_1 = \norm*{(- \mathcal L_{\rm ovd})^{1/2} h} = \sqrt{\ip{\mathcal L_{\rm ovd} h}{h}} = \norm{\partial_q h},
    \]
    so~\eqref{eq:exponential_convergence} implies the exponential convergence of $\norm{\partial_q u}$.
    For $i = 2$, we calculate using the commutator relation $\commut{\partial_q}{\partial_q^*} = \beta V''$ that
    \[
        \seminorm{h}_2^2 = \norm*{- \mathcal L_{\rm ovd}f}^2
        = \ip{\partial_q^* \partial_q h}{\partial_q^* \partial_q h}
        = \norm*{\partial_q^2 h}^2 + \ip{V'' \partial_q h}{\partial_q h}.
    \]
    Therefore~\eqref{eq:exponential_convergence} implies that
    \begin{align*}
        \norm*{\partial_q u}^2
        &\leq \abs{\ip{V'' \partial_q u}{\partial_q u}} + \e^{-4Rt} \bigl( \norm{\partial_q^2 u(0)}^2 + \ip{V'' \partial_q u(0)}{\partial_q u(0)} \bigr) \\
        &\leq \norm*{V''}_{\infty} \norm{\partial_q u}^2 + \e^{-4Rt} \bigl( \norm{\partial_q^2 u(0)}^2 + \norm*{V''}_{\infty} \norm*{\partial_q u(0)}^2 \bigr),
    \end{align*}
    and using the exponential convergence of the first term on the right-hand side,
    which was proved in the previous step,
    allows to conclude that $\norm*{\partial_q^2 u} \leq K \e^{-2 Rt} \norm*{u}^2$ for some an appropriate constant $K \geq 1$.
    This procedure can then be repeated in order to deduce the statement.
\end{proof}
\begin{remark}
    An alternative approach for showing~\cref{lemma:overdamped_langevin_decay_derivatives} is
    to define an auxiliary norm
    \[
        ||| u |||_N^2 = \norm*{u}^2 + a_1 \norm*{\partial_q u}^2 + \dotsc + a_N \norm*{\partial_q^N u}^2,
    \]
    with coefficients $a_i = \varepsilon^i$ for some $\varepsilon \in (0, 1)$.
    This norm is equivalent to the weighted Sobolev norm $\norm*{u}_N$,
    and it is possible to show for all $\lambda \in (0, 1)$ that
    \[
        \frac{1}{2}\derivative*{1}{t} |||u|||_N^2 \leq - 2 R(1 - \lambda) \, |||u|||_N^2
    \]
    for $\varepsilon$ sufficiently small.
    The reason for the suboptimal rate here is that the term $\norm{\partial_q u}^2$,
    obtained from $\frac{1}{2} \partial_t \norm*{u}^2$,
    needs to control the two terms $\norm{u}^2 + a_1 \norm{\partial_q u}^2$.
\end{remark}

\bibliographystyle{plain}
\bibliography{main}
\end{document}

\begin{proof}
    The general Leibniz rule gives that, for two smooth functions $f(q)$ and $g(q)$,
    \[
        \left( fg \right)^{(N)}
        = \sum_{k=0}^{N} {N \choose k} f^{(k)} g^{(N-k)}.
    \]
    Therefore,
    \begin{equation}
        \label{eq:commutators}
        \commut{\partial_q^N}{f}
        = \sum_{k=1}^{N} {N \choose k} f^{(k)} \partial_q^{(N-k)}.
    \end{equation}
    Let $\partial_q^* = \beta V' - \partial_q$.
    It follows from~\eqref{eq:commutators} that
    \[
        \commut{\partial_q^N}{\partial_q^*}
        = \commut{\partial_q^N}{\beta V' - \partial_q}
        = \beta \commut{\partial_q^N}{V'}
        = \beta \sum_{k=1}^{N} {N \choose k} V^{(k+1)} \partial_q^{(N-k)}.
    \]
    Let $||| u |||_N^2 = \norm*{u}^2 + a_1 \norm*{\partial_q u}^2 + \dotsc + a_N \norm*{\partial_q^N u}^2$,
    with coefficients $a_i = \varepsilon^i$ for some $\varepsilon \in (0, 1)$ that will be defined later.
    Noting that $\mathcal L_{\rm ovd} = - \partial_q^* \partial_q$,
    we obtain
    \begin{align}
        \notag
        \frac{1}{2} \derivative*{1}{t} |||u|||_N^2
        &= - \ip{\partial_q^*\partial_q u}{u} - a_1 \ip{\partial_q \partial_q^* \partial_q u}{\partial_q u} - \dotsb - a_N \ip{\partial_q^N \partial_q^* \partial_q u}{\partial_q^N u} \\
        \notag
        &= - \norm*{u'}^2 - a_1 \norm*{u''}^2 - \dotsb - a_N \norm*{u^{(N+1)}}^2 \\
        \label{eq:derivative_norm}
        &\hspace{5cm} - \beta \sum_{i=1}^{N} a_i \sum_{k=1}^{i} {i \choose k} \ip*{V^{(k+1)} u^{(i-k+1)}}{u^{(i)}}.
    \end{align}
    In order to bound the last term,
    we define
    \[
        M = \frac{\beta}{2} N^N \left( \max_{i \in \{0, 1, \dotsc, N\}} \norm*{V^{(i)}}_{\infty}^2 + 1 \right).
    \]
    Using Young's inequality and the fact that $a_i \geq a_j$ if $i \leq j$, we have
    \begin{align*}
        - \beta \sum_{i=1}^{N} a_i \sum_{k=1}^{i} {i \choose k} \ip*{V^{(k+1)} u^{(i-k+1)}}{u^{(i)}}
        &\leq \frac{\beta}{2} \sum_{i=1}^{N} a_i \sum_{k=1}^{i} {i \choose k} \left( \norm*{V^{(k+1)} u^{(i+1-k)}}^2 + \norm*{u^{(i)}}^2 \right) \\
        &\leq M \sum_{i=1}^{N} a_i \sum_{k=1}^{i} \left( \norm*{u^{(i+1-k)}}^2 + \norm*{u^{(i)}}^2 \right)
        \leq 2 M N \sum_{i=1}^{N} a_i \norm*{u^{(i)}}^2.
    \end{align*}
    Employing this bound in~\eqref{eq:derivative_norm} and choosing $\varepsilon = \frac{\lambda}{2 MN}$ for some $\lambda \in (0, \frac{1}{2})$,
    we obtain
    \begin{align*}
        \notag
        \frac{1}{2} \derivative*{1}{t} |||u|||_N^2
        &\leq - (1 - 2MN a_1) \norm*{\partial_q u}^2 - (a_1 - 2MN a_2) \norm*{\partial_q^2 u}^2 - \dotsb - (a_{N-1} - 2MN a_{N}) \norm*{\partial_q^N u}^2 \\
        &\leq - \left( 1 - \lambda \right) \norm{\partial_q u}^2 - \left( 1 - \lambda \right) \varepsilon \norm*{\partial_q^2 u}^2 - \dotsb - \left( 1 - \lambda \right) \varepsilon^{N-1} \norm*{\partial_q^N u}^2 \\
        &\leq - 2 \alpha R \norm{u}^2 - (1 - \alpha)(1 - \lambda) \norm{\partial_q u}^2 - \varepsilon^2 \norm*{\partial_q^2 u}^2 - \dotsb - \varepsilon^N \norm*{\partial_q^N u}^2 \qquad \forall \alpha \in (0, 1).
    \end{align*}
    Choosing $\alpha$ such that $(1 - \alpha)(1 - \lambda) = \varepsilon$,
    we obtain $\frac{1}{2} \partial_t |||u|||_N^2 \leq - 2 R (1 - \lambda) |||u|||^2$,
    which leads by Gr\"onwall's inequality to the exponential convergence estimate
    \[
        \forall t \geq 0, \qquad |||u(t)|||_N^2 \leq \e^{-2 R (1 - \lambda) t} |||u(0)|||_N^2.
    \]
    Using the equivalence of between the norms $\norm{\dummy}_N$ and $|||\dummy|||_N$ allows to conclude.
    \textcolor{red}{Not sharp!}
\end{proof}
