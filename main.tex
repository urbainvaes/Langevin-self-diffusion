\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{graphicx}
\usepackage{array}
\usepackage{verbatim}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath,amsthm,amsfonts,amssymb,latexsym}
\usepackage{bbm}
\usepackage{setspace}
\usepackage{xparse}
\usepackage{epstopdf}
\usepackage{pgf}
\usepackage[colorlinks=true,citecolor=blue]{hyperref}
\usepackage[nameinlink,capitalise]{cleveref}

\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{pgfplotstable}
\pgfplotsset{compat=1.14}
\usetikzlibrary{patterns}
\usetikzlibrary{calc}
\usetikzlibrary{angles}
\usetikzlibrary{quotes}
\usetikzlibrary{external}

\onehalfspacing
% \setlength{\parskip}{6pt}

\DeclareDocumentCommand\abs{s m} {\IfBooleanTF{#1}{\left|#2\right|}{\left|#2\right|}}
\DeclareDocumentCommand\cont{o m o} {C\IfNoValueF{#1}{^{#1}}(#2\IfNoValueF{#3}{;#3})}
\DeclareDocumentCommand\contc{o m o} {C_c\IfNoValueF{#1}{^{#1}}(#2\IfNoValueF{#3}{;#3})}
\DeclareDocumentCommand\sobolev{m m o} {H^{#1}(#2 \IfNoValueF{#3}{,#3})}
\DeclareDocumentCommand\lp{m m o} {L^{#1}\left(#2 \IfNoValueF{#3}{,#3}\right)}
\DeclareDocumentCommand\norm{s m o} {\IfBooleanTF{#1}{\|#2\|}{\left\|#2\right\|}\IfNoValueF{#3}{_{#3}}}
\DeclareDocumentCommand\seminorm{m o o} {\left|#1\right|\IfNoValueF{#2}{_{#2 \IfNoValueF{#3}{,#3}}}}
\DeclareDocumentCommand\ip{s m m o} {\IfBooleanTF{#1}{\langle #2,#3 \rangle}{\left\langle #2,#3 \right\rangle}\IfNoValueF{#4}{_{#4}}}
\DeclareDocumentCommand\dup{m m o} {\left\langle{#1,#2}\right\rangle\IfNoValueF{#3}{_{#3', #3}}}
\DeclareDocumentCommand\gaussian{O{0} O{I}} {g_{#1, #2}}
\DeclareDocumentCommand\littleo{s o m} {o\IfNoValueF{#2}{_{#2}}\IfBooleanTF{#1}{(#3)}{\left(#3\right)}}
\DeclareDocumentCommand\bigo{s o m} {\mathcal O\IfNoValueF{#2}{_{#2}}\IfBooleanTF{#1}{(#3)}{\left(#3\right)}}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\re}{Re}
\DeclareMathOperator*{\trace}{tr}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\sym}{sym}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\e}{e}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\offdiag}{offdiag}

\newcommand{\revision}[1]{\textcolor{blue}{#1}}
\renewcommand{\revision}[1]{#1}
\newcommand{\gab}[1]{\textcolor{darkgreen}{#1}}
\newcommand{\commut}[2]{[#1, #2]}
\newcommand{\correlation}[1]{\left< #1 \right>}
\newcommand{\dummy}{\,\cdot\,}
\newcommand{\expect}[0]{\mathbf{E}}
\newcommand{\var}[0]{\mathbf{V}}
\newcommand{\iip}[2]{\left(\!\left(#1, #2\right)\!\right)}
\newcommand{\nat}{\mathbf N}
\newcommand{\poly}{\mathbf P}
\newcommand{\real}{\mathbf R}
\newcommand{\integer}{\mathbf Z}
\newcommand{\torus}{\mathbf T}
\newcommand{\grad}{\boldsymbol \nabla}
\newcommand{\hess}{\nabla^2}
\newcommand{\vect}[1]{\boldsymbol{\mathbf #1}}
\newcommand{\mat}[1]{\vect #1}
\renewcommand{\det}[1]{\mathrm{det} \left( #1 \right)}
\renewcommand{\d}{\mathrm d}
\renewcommand{\t}{\mathsf T}
% \renewcommand{\t}{t}

\makeatletter
\DeclareDocumentCommand \derivative{s m o m}{%
    \def\@der{\IfBooleanTF{#1}{\mathrm{d}}{\partial}}
    \def\@default{%
        \mathchoice{%
                \frac{%
                    \@der\ifnum\pdfstrcmp{#2}{1}=0\else^{#2}\fi {\IfNoValueTF{#3}{}{#3}}
                }{%
                    \@for\@token:={#4}\do{\@der \@token}
                }
            } {%
                \@for\@token:={#4}\do{\@der_\@token} \IfNoValueTF{#3}{}{#3}
            } {} {}
    }
    \IfBooleanTF{#1}{\IfNoValueTF{#3}{\@default}{%
                #3%
                \ifnum\pdfstrcmp{#2}{1}=0'\else%
                \ifnum\pdfstrcmp{#2}{2}=0''\else%
                \ifnum\pdfstrcmp{#2}{3}=0^{(3)}\else%
                \ifnum\pdfstrcmp{#2}{4}=0^{(4)}\else%
                \ifnum\pdfstrcmp{#2}{5}=0^{(5)}\else%
                ^{(#2)}\fi\fi\fi\fi\fi
            }
        }{\@default}
}
\makeatother

\definecolor{darkred}{rgb}{.5,0,0}
\definecolor{darkgreen}{rgb}{0,.5,0}
\definecolor{darkblue}{rgb}{0,0,.5}
\newcommand{\red}[1]{\textcolor{darkred}{#1}}
\newcommand{\green}[1]{\textcolor{darkgreen}{#1}}

\theoremstyle{plain}
\newtheorem{assumption}{Assumption}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{result}{Result}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\numberwithin{equation}{section}

\newcounter{urbainCounter}
\newcommand{\urbain}[1]{\stepcounter{urbainCounter}\red{\arabic{urbainCounter}.} \green{#1}}
\crefname{equation}{}{}
\crefname{paragraph}{\S\!}{\S}
% \crefname{figure}{Figure}{Figures}
% \crefname{section}{Section}{Sections}

\newcommand{\email}[1]{\href{#1}{#1}}
\newcommand{\orcidcolor}{ORC\textcolor{orcidlogocol}{ID}}
\newcommand{\orcid}[1]{\href{https://orcid.org/#1}{\includegraphics[width=.4cm]{z_orcid.pdf}}}

%---------------- GABRIEL ------------
\usepackage{enumerate}
\newcommand{\eps}{\varepsilon}
\newcommand{\dps}{\displaystyle}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\ri}{\mathrm{i}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
% \usepackage{todonotes}
\usepackage{mathrsfs}

% BODY {{{1
\date{\today}
\title{Variance reduction for calculating the effective diffusion coefficient of Langevin dynamics}
\author{%
  % G.A. Pavliotis\thanks{Department of Mathematics, Imperial College London (\email{g.pavliotis@imperial.ac.uk})}%
  % \hspace{2mm}\orcid{0000-0002-3468-9227}%
  % \and G. Stoltz\thanks{CERMICS, \'Ecole des Ponts, France \& MATHERIALS, Inria Paris (\email{gabriel.stoltz@enpc.fr})}
  % \hspace{2mm}\orcid{0000-0002-2797-5938}%
  % \and U. Vaes\thanks{Department of Mathematics, Imperial College London (until October 2020) and MATHERIALS, Inria Paris (since November 2020) (\email{urbain.vaes@inria.fr})}%
  % \hspace{2mm}\orcid{0000-0002-7629-7184}%
}

\begin{document}
\maketitle

\section{Introduction}%
Let us first consider the Langevin dynamics in one dimension:
\begin{subequations}
\begin{align}
    \label{eq:Langevin_q}
    \d q &= p \, \d t, \\
    \label{eq:Langevin_p}
    \d p &= - \derivative*{1}[V]{q}(q) \, \d t - \gamma p \, \d t + \sqrt{2 \gamma \beta^{-1}} \d W_t.
\end{align}
\end{subequations}
The generator of the associated Markov semigroup is given by
\[
    \mathcal L = p \derivative{1}{q} - \derivative*{1}[V]{q}(q) \derivative{1}{p} + \gamma \left( - p \derivative{1}{p} + \beta^{-1} \derivative{2}{p^2} \right).
\]
Let $\phi$ denote the solution to
\[
    - \mathcal L \phi = p,
\]
and suppose that $\psi$ denote an approximation of $\phi$.
By It\^o's formula, it holds
\begin{align*}
    \phi(q_t, p_t) - \phi(q_0, p_0) &= - \int_{0}^{t} p_s \, \d s + \sqrt{2 \gamma \beta^{-1}} \int_{0}^{t} \derivative{1}[\phi]{p}(q_s, p_s) \, \d W_s \\
    \psi(q_t, p_t) - \psi(q_0, p_0) &= \int_{0}^{t} (\mathcal L \psi) (q_s, p_s) \, \d s + \sqrt{2 \gamma \beta^{-1}} \int_{0}^{t} \derivative{1}[\psi]{p}(q_s, p_s) \, \d W_s.
\end{align*}
Let also $u(t)$ and $v(t)$ denote the random variables
\[
    u(t) = \frac{\abs{q_t - q_0}^2}{2t}
\]
and
\begin{align*}
    v(t) &= D_{\psi}+ \frac{1}{2t} \left( \abs{q_t - q_0}^2 - \abs{\xi_t}^2\right)
\end{align*}
where $D_{\psi} := \gamma \beta^{-1} \int_{\torus \times \real} \abs{\derivative{1}[\psi]{p}}^2 \, \d \mu$ and
 \[
    \xi_t = \psi(q_t, p_t) - \psi(q_0, p_0) - \sqrt{2 \gamma \beta^{-1}} \int_{0}^{t} \derivative{1}[\psi]{p}(q_s, p_s) \, \d W_s
 \]
It holds
\[
    \lim_{t \to \infty} \expect \bigl( u(t) \bigr) = \lim_{t \to \infty} \expect \bigl( v(t) \bigr)
    = \gamma \beta^{-1} \int_{\torus \times \real} \abs{\derivative{1}[\phi]{p}}^2 \, \d \mu
    = \int_{\torus \times \real} \phi \, p \, \d \mu =: D_{\phi}.
\]
so both $u(t)$ and $v(t)$ are asymptotically unbiased estimators of $D_{\phi}$.

\paragraph{Bias of the estimator.}%

\begin{proposition}
    [Bias of the estimator]
    Assume stationary initial conditions $(q_0, p_0) \sim \mu$.
    Then
    \begin{align*}
        \forall t > 0, \quad \gamma > 0, \qquad
        \abs{\expect \bigl( v(t) \bigr) - D_{\phi}}
        \leq \frac{c_1}{c_2^2 t} \, \max(\gamma^2, \gamma^{-2}) \norm{\mathcal L\psi + p}  \left(1 + \norm{\mathcal L \psi} \right).
    \end{align*}
\end{proposition}
\begin{proof}
    For an observable $\zeta = \zeta(q, p)$ in $\lp{2}{\mu} \cap \mathcal D(\mathcal L)$,
    we denote $C_{\zeta}(s) := \ip{\mathcal L \zeta}{\e^{s \mathcal L} \mathcal L \zeta}$.
    With this notation, $C_{\phi}$ is the autocorrelation function of the momentum function $(q, p) \mapsto p$.
    It is well known~\cite{roussel2018spectral} that $\norm*{ \e^{s \mathcal L} }[\mathcal B \left(L^2_0\left(\mu\right) \right)] \leq M \exp \bigl(- \hat \lambda s \min(\gamma, \gamma^{-1}) \bigr)$
    for appropriate constants $M > 0$ and $\hat \lambda > 0$,
    so we obtain, using It\^o's isometry,
    \begin{align*}
        \expect \bigl(v(t)\bigr) - D_{\phi}
        &= D_{\psi} + \int_{0}^{t} \left(1 - \frac{s}{t}\right) \bigl( C_{\phi}(s) - C_{\psi}(s) \bigr) \, \d s. \\
        &= D_{\phi} - \int_{0}^{\infty} \min\left(1, \frac{s}{t}\right) \bigl( C_{\phi}(s) - C_{\psi}(s) \bigr) \, \d s,
    \end{align*}

    \begin{align*}
        \expect \bigl(u(t)\bigr)
        &= \frac{1}{2t} \expect \left( \int_{0}^{t} p_s \, \d s \int_{0}^{t} p_u \, \d u \right)
        = \frac{1}{2t} \left( \int_{0}^{t} \int_{0}^{t} \expect (p_s p_u) \, \d s \, \d u \right) \\
        &= \frac{1}{2t} \left( \int_{0}^{t} \int_{0}^{t} C_{\phi}(\abs{s - u}) \, \d s \, \d u \right)
        =  \int_{0}^{t} C_{\phi}(s) \left(1 - \frac{s}{t}\right) \d s  \\
        &= D_{\phi} - \int_{0}^{\infty} \min\left(1, \frac{s}{t}\right) C_{\phi}(s) \, \d s.
    \end{align*}
Since $\abs{C_{\phi}(s)} = \abs{\ip{p}{\e^{s \mathcal L} p}} \leq \norm{p} \, \norm{\e^{s \mathcal L} p} \leq \beta^{-1} c_1 \exp\bigl( - c_2 \min(\gamma, \gamma^{-1}) t\bigr)$, it holds
\[
    \forall t > 0, \quad \gamma > 0, \qquad
    \abs{\expect\bigl(u(t)\bigr) - D_{\phi}}
    \leq \frac{1}{t}\int_{0}^{\infty} s C_{\phi}(s) \, \d s
    \leq \frac{c_1}{c_2^2 t} \, \max\bigl(\gamma^{-2}, \gamma^2\bigr).
\]
It is well known that $D_{\phi} = \mathcal O(\gamma^{-1})$ in both the limit $\gamma \to 0$ and the limit $\gamma \to \infty$.
Therefore, the relative bias scales as $\max(\gamma^{-1}, \gamma^3) / t$.
Applying the same reasoning to $v(t)$, we obtain
\begin{align*}
    \expect \bigl(v(t)\bigr)
    &= D_{\psi} + \int_{0}^{t} \left(1 - \frac{s}{t}\right) \bigl( C_{\phi}(s) - C_{\psi}(s) \bigr) \, \d s. \\
    &= D_{\phi} - \int_{0}^{\infty} \min\left(1, \frac{s}{t}\right) \bigl( C_{\phi}(s) - C_{\psi}(s) \bigr) \, \d s,
\end{align*}
where $C_{\psi}(s) = \ip{\mathcal L \psi}{\e^{s \mathcal L} \mathcal L \psi}$.
We have
\begin{align*}
    C_{\phi}(s) - C_{\psi}(s)
    &= \ip{\mathcal L (\phi - \psi)}{\e^{s \mathcal L} \mathcal L \phi + \e^{s \mathcal L^*} \mathcal  L\psi} \\
    &\leq \norm{\mathcal L(\phi - \psi)}
    \left( \norm*{\e^{s \mathcal L}}[\mathcal B\left(L^2_0(\mu) \right)] \norm{\mathcal L \phi} + \norm*{\e^{s \mathcal L^*}}[\mathcal B\left(L^2_0(\mu) \right)] \norm{\mathcal L \psi} \right) \\
    &\leq c_1 \e^{-c_2 \min(\gamma, \gamma^{-1}) s} \norm{\mathcal L\psi + p}  \left(1 + \norm{\mathcal L \psi} \right),
\end{align*}
which concludes the proof.
\end{proof}

\begin{example}
    [Case of a quadratic potential]
    Consider the case of the quadratic confining potential $V(q) = \frac{k q^2}{2}$.
    In this case, the eigenfunctions of $\mathcal L$ are polynomials,
    with the linear ones and associated eigenvalues being
    \[
        v_{\pm}(q, p) =
        \left( \frac{\gamma \pm \sqrt{\gamma^2 - 4k}}{2} \right) q + p, \\
        \qquad
        \lambda_{\pm} = \frac{- \gamma \pm \sqrt{\gamma^2 - 4k}}{2}.
    \]
    The function $(q, p) \mapsto p$ is the following linear combination of these eigenfunctions:
    \[
        p =
        \left( \frac{-\gamma + \sqrt{\gamma^2 - 4k}}{2 \sqrt{\gamma^2 - 4k}} \right) v_+
        + \left( \frac{\gamma + \sqrt{\gamma^2 - 4k}}{2 \sqrt{\gamma^2 - 4k}} \right) v_-.
    \]
    Therefore, given that $\ip{v_+}{p} = \ip{v_-}{p} = \beta^{-1}$,
    the velocity autocorrelation function is
    \[
        \ip{\e^{t \mathcal L}p}{p} =
        \left( \frac{-\gamma + \sqrt{\gamma^2 - 4k}}{2 \beta \sqrt{\gamma^2 - 4k}} \right) \e^{\lambda_+ t} +
        \left( \frac{\gamma + \sqrt{\gamma^2 - 4k}}{2 \beta \sqrt{\gamma^2 - 4k}} \right) \e^{\lambda_- t} = T_1(t) + T_2(t).
    \]
    Although $\lambda_+ = \bigo {\gamma^{-1}}$ as $\gamma \to \infty$,
    it holds that $\int_{0}^{\infty} T_1(t) \, \d t = \bigo{\gamma^{-1}}$
    because the factor multiplying the exponential scales as $\bigo {\gamma^{-2}}$.
\end{example}


which leads to
\begin{align*}
    \forall t > 0, \quad \gamma > 0, \qquad
    \abs{\expect \left( v(t) \right) - D_{\phi}}
    \leq \frac{c_1}{c_2^2 t} \, \max(\gamma^2, \gamma^{-2}) \norm{\mathcal L\psi + p}  \left(1 + \norm{\mathcal L \psi} \right).
\end{align*}
The constant on the right-hand side is smaller when $\psi \approx \phi$,
and when $\psi = 0$ we recover the previous bound.

\begin{example}
    Consider the case where $V(q) = 0$.
    In this case, the solution to the Poisson equation $- \mathcal L \phi = p$ is given by $\phi(q, p) = \gamma^{-1} p$ and,
    applying Itô's formula to this function, we obtain
    (note that this equation can be derived directly from~\eqref{eq:Langevin_p})
    \[
        \gamma^{-1}(p_t - p_0) = - \int_{0}^{t} p_s \, \d s + \sqrt{2 \gamma^{-1} \beta^{-1}} (W_t - W_0)
        = q_0 - q_t + \sqrt{2 \gamma^{-1} \beta^{-1}} W_t.
    \]
    We deduce, using the explicit solution to the Ornstein--Uhlenbeck equation satisfied by $p$, that
    \begin{align*}
        q_t - q_0
        &= - \gamma^{-1} \left( p_0 \left(\e^{-\gamma t} - 1\right) + \sqrt{2 \gamma \beta^{-1}}\int_{0}^{t} \e^{-\gamma (t - s)} \, \d W_s \right)
        + \sqrt{2 \gamma^{-1} \beta^{-1}} W_t \\
        &=  - \gamma^{-1} p_0 \left(\e^{-\gamma t} - 1\right) + \sqrt{2 \gamma^{-1} \beta^{-1}}\int_{0}^{t} \left(1 - \e^{-\gamma (t - s)}\right) \, \d W_s.
    \end{align*}
    Assuming $p_0 \sim \mathcal N(0, \beta^{-1})$,
    the right-hand side of this equation is a mean-zero Gaussian random variable and,
    using It\^o's isometry, we calculate that
    \[
        \frac{\expect \abs{q_t - q_0}^2}{2t} = \gamma^{-1} \beta^{-1} \left( 1 + \frac{1}{t \gamma} \left(\e^{-\gamma t} - 1\right) \right)
    \]
\end{example}

\paragraph{Variance of the estimator.}%
For the variance, we can obtain a crude bound using
\begin{align*}
    \mathrm{Var} (v(t))
    &\leq \expect \left( \abs{v(t) - D_{\psi}}^2 \right)
    = \frac{1}{4 t^2} \expect \big( |q_t - q_0 - \xi_t|^2 |q_t - q_0 + \xi_t|^2 \big) \\
    &\leq \frac{1}{4 t^2} \sqrt{\expect \left(  |q_t - q_0 - \xi_t|^4 \right)} \sqrt{\expect \left( |q_t - q_0 + \xi_t|^4 \right)}.
\end{align*}
We now bound
\begin{align*}
    \expect \left( |q_t - q_0 + \xi_t|^4 \right)
    &= \expect \left( \abs{\phi_t - \phi_0 - \psi_t + \psi_0 + I_{\psi} - I_{\phi}}^4 \right) \\
    &\leq 3^3 \left( \expect \left( \abs{\phi_t - \psi_t}^4 \right) + \expect \left( \abs{\phi_0 - \psi_0}^4 \right) + \expect \left( \abs{I_{\psi} - I_{\phi}}^4 \right) \right).
\end{align*}
The first two terms are bounded by $\norm{\phi - \psi}_{L^4(\mu)}^4$.
Using a moment inequality for It\^o integrals, the last term can be bounded as
\[
    \expect \left( \abs{I_{\psi} - I_{\phi}}^4 \right) \leq 6 t \expect \int_{0}^{t} \abs{\derivative{1}[\phi]{p}(q_s, p_s) - \derivative{1}[\psi]{p}(q_s, p_s)}^4 \, \d s = 6 t \int \abs{\derivative{1}[\phi]{p} - \derivative{1}[\psi]{p}}^4 \d \mu.
\]
Likewise, the other term can be bounded as
\begin{align*}
    \expect \left( |q_t - q_0 - \xi_t|^4 \right)
    &\leq 3^3 \left( \expect \left( 2 \norm{\phi + \psi}[L^4(\mu)]^4 + 6 t \norm{\derivative{1}[\phi]{p} + \derivative{1}[\psi]{p}}[L^{4}(\mu)]^4 \right) \right).
\end{align*}

% \paragraph{Estimator diffusion coefficient.}%
% \label{par:estimator_diffusion_coefficient}

% Let $U_t = \sqrt{2 D} W_t$ and consider the estimator
% \[
%     2 \hat D = \frac{t_1 U_{t_1}^2 + \dotsb + t_N U_{t_N}^2}{t_1^2 + \dotsb + t_N^2},
% \]
% where $t_i = i \Delta_t$.
% This estimator is clearly unbiased: $\expect (\hat D) = D$.
% Let $\xi_i = (U_{t_{i}} - U_{t_{i-1}})/\sqrt{2D \Delta t}$, for $i = 1, \dotsc, N$.
% It holds
% \begin{align*}
%     \frac{\hat D - D}{D}
%     &= 6 \left( \frac{ \sum_{i=1}^{N} \sum_{j=i}^{N} (\xi_i ^2 - 1)  j  + 2 \sum_{i=1}^{N} \sum_{j=i+1}^{N} \sum_{k=i}^{j} \xi_i \xi_j k}
%     {1 + \dotsb + N^2} \right) \\
%     &= 3 \left( \frac{ \sum_{i=1}^{N} (\xi_i ^2 - 1)  (N+1-i)(N+i)  + 2 \sum_{i=1}^{N} \sum_{j=i+1}^{N} \xi_i \xi_j (j+1-i)(j+i)}
%     { N(N+1)(2N+1)} \right).
% \end{align*}
% We calculate
% \begin{align*}
%     \expect \abs{ \frac{\hat D - D}{D} }^2
%     &= 9 \left( \frac{ \sum_{i=1}^{N} \expect (\xi_i ^4 + 1 - 2 \xi_i^2)  (N+1-i)^2 (N+i)^2}
%     { N^2 (N+1)^2 (2N+1)^2} \right) \\
%     &\quad + 36 \left(  \frac{\sum_{i=1}^{N} \sum_{j=i+1}^{N} \expect \left( \abs{\xi_i}^2 \abs{\xi_j}^2 \right) \abs{j+1-i}^2 \abs{j+i}^2}
%     { N^2 (N+1)^2 (2N+1)^2} \right) \\
%     &= 18 \left( \frac{ \sum_{i=1}^{N}  (N+1-i)^2 (N+i)^2}
%     { N^2 (N+1)^2 (2N+1)^2} \right)
%     + 36 \left(  \frac{\sum_{i=1}^{N} \sum_{j=i+1}^{N} \abs{j+1-i}^2 \abs{j+i}^2}
%     { N^2 (N+1)^2 (2N+1)^2} \right).
% \end{align*}
\appendix
\section{Auxiliary technical results}%
\label{sec:auxiliary_technical_results}

In order to state the results, we define the probability measures
\begin{equation}
    \label{eq:definition_prob_measures}
    \nu(\d q) = \frac{\e^{- \beta V(q)} \, \d q}{\int_{\torus^d}\e^{-\beta V(\widetilde q)} \d \widetilde q},
    \qquad \kappa(\d p) = \left( \frac{\beta}{2 \pi} \right)^{d/2}\exp \left( - \beta \frac{\abs{p}^2}{2} \right) \d p.
\end{equation}
We also define $\partial_q^* = \beta V'(q) - \partial_q$ and $\partial_p^* = \beta p - \partial_p$,
and note that these operators are formally the $L^2(\mu)$ adjoints of $\partial_q$ and $\partial_p$.

\begin{lemma}
    Assume that $f(q, p) = Q(q) P(p)$ for smooth functions $Q \in H^1(\nu)$ and $P \in H^1_0(\kappa)$.
    Then there exist constants $C$ and $\lambda$ such that
    \[
        \forall \gamma > 1, \qquad
        \forall t \geq 0, \qquad
        \norm*{\e^{t\mathcal L} f}
        \leq C \norm*{Q}_1 \norm*{P}_1
        \left( \e^{- \gamma t} + \gamma \e^{-\frac{t}{\gamma}} \right).
    \]

\end{lemma}

\begin{proof}
    We consider the following decomposition of the generator:
    \[
        \mathcal L
        = \left( p \derivative{1}{q} - \derivative*{1}[V]{q}(q) \derivative{1}{p} \right)
        + \gamma \left( - p \derivative{1}{p} + \beta^{-1} \derivative{2}{p^2} \right)
        =: \mathcal L_{\rm Ham} + \gamma \mathcal L_{\rm FD}.
    \]
    Let $v(t) = \e^{t \mathcal L} f(q, p) - Q(q) \e^{- t \gamma \mathcal L_{\rm FD}} P(p)$.
    The function $v$ satisfies the initial value problem
    \[
        \partial_t v = \mathcal L v +  \mathcal L_{\rm Ham} \bigl(Q(q) \e^{t \gamma \mathcal L_{\rm FD}} P(p)\bigr), \qquad v(0) = 0.
    \]
    Using Duhamel's formula, we have
    \[
        v(t) = \int_{0}^{t} \e^{- (t-s) \mathcal L}  \Bigl( \mathcal L_{\rm Ham} \bigl(Q(q) \e^{s \gamma \mathcal L_{\rm FD}} P(p)\bigr) \Bigr) \, \d s,
    \]
    and therefore
    \begin{equation}
        \label{eq:intermediate_decay_correlation}
        \e^{t \mathcal L} f(q,p) = Q(q) \e^{t \gamma \mathcal L_{\rm FD}} P(p)
        + \int_{0}^{t} \e^{- (t-s) \mathcal L}  \Bigl( \mathcal L_{\rm Ham} \bigl(Q(q) \e^{s \gamma \mathcal L_{\rm FD}} P(p)\bigr) \Bigr) \, \d s.
    \end{equation}
    We calculate
    \begin{align*}
        \mathcal L_{\rm Ham} \bigl(Q(q) \e^{t \gamma \mathcal L_{\rm FD}} P(p)\bigr)
        &= Q'(q) p \e^{t \gamma \mathcal L_{\rm FD}} P(p) - V'(q) Q(q) \partial_p(\e^{t \gamma \mathcal L_{\rm FD}} P) (p) \\
        &=: Q^t_1(q) P^t_1(p) + Q^t_2(q) P^t_2(p).
    \end{align*}
    From \cref{lemma:overdamped_langevin_decay_derivatives} and the fact that $\kappa$ satisfies~\eqref{eq:poincare} with constant $R = \frac{1}{2}$,
    we immediately obtain the bound
    \(
        \norm{P^t_2} \leq \e^{-2\gamma t} \norm*{P'}.
    \)
    Likewise,
        % &= \ip{\partial_p (\e^{t \gamma \mathcal L_{\rm FD}} P)}{\partial_p (\e^{t \gamma \mathcal L_{\rm FD}} P)}
        % = - \ip{\partial_p^* \partial_p (\e^{t \gamma \mathcal L_{\rm FD}} P)}{\e^{t \gamma \mathcal L_{\rm FD}} P} \\
        % &= - \ip{\mathcal L_{\rm FD} (\e^{t \gamma \mathcal L_{\rm FD}} P)}{\e^{t \gamma \mathcal L_{\rm FD}} P}
        % = - \ip{\mathcal L_{\rm FD}^{1/2} (\e^{t \gamma \mathcal L_{\rm FD}} P)}{\mathcal L_{\rm FD}^{1/2} (\e^{t \gamma \mathcal L_{\rm FD}} P)} \\
        % &= - \norm*{\e^{t \gamma \mathcal L_{\rm FD}} (\mathcal L_{\rm FD}^{1/2}P)}^2 \leq \e^{-2\gamma t} \norm*{\mathcal L_{\rm FD}^{1/2} P}^2
        % = \e^{-2\gamma t} \norm*{P'}^2,
    \begin{align*}
        \norm{\partial_p^* \e^{t \gamma \mathcal L_{\rm FD}} P}^2
        &= \ip{\partial_p \partial_p^*\e^{t \gamma \mathcal L_{\rm FD}} P}{\e^{t \gamma \mathcal L_{\rm FD}} P}
        = \ip{(\beta  + \partial_{p}^* \partial_p) \e^{t \gamma \mathcal L_{\rm FD}} P}{\e^{t \gamma \mathcal L_{\rm FD}} P} \\
        &= \beta \norm*{\e^{t \gamma \mathcal L_{\rm FD}} P}^2 + \norm{\partial_p \mathcal L_{\rm FD} \e^{t \gamma \mathcal L_{\rm FD}} P}^2
        \leq \e^{-2\gamma t} \left( \beta \norm*{P}^2 + \norm*{P'}^2 \right),
    \end{align*}
    so $\norm{P^t_1} = \beta^{-1} \norm{ (\partial_p^* - \partial_p) \e^{t \gamma \mathcal L_{\rm FD}} P(p)} \leq \e^{- \gamma t} (\beta^{-1/2}\norm{P} +  2\beta^{-1}\norm{P'})$.
    In addition, it holds that $\norm{Q_1} + \norm{Q_2} \leq C \norm{Q}_1$,
    so we deduce
    \[
        \norm{\mathcal L_{\rm Ham} \bigl(Q(q) \e^{t \gamma \mathcal L_{\rm FD}} P(p)\bigr)}
        \leq C \e^{-\gamma t} \norm{Q}_1 \norm{P}_1.
    \]
    Going back to~\eqref{eq:intermediate_decay_correlation} and using~\eqref{eq:decay_langevin}, we deduce
    \begin{align*}
        \norm*{ \e^{t \mathcal L} f(q,p) }
        &\leq \norm{Q} \norm{P} \e^{-\gamma t}
        + C \norm{Q}_1 \norm{P}_1 \int_{0}^{t} \e^{-\frac{\lambda_{\rm Lang}}{\gamma}(t-s)}  \, \e^{-\gamma s} \, \d s \\
        &\leq \norm{Q} \norm{P} \e^{-\gamma t}
        + C \norm{Q}_1 \norm{P}_1
        \left( \frac{\e^{- \frac{\lambda_{\rm Lang}}{\gamma}t} - \e^{- \gamma t}}{\gamma - \frac{\lambda_{\rm Lang}}{\gamma}} \right) \qquad \forall \gamma \geq 1.
    \end{align*}
    We can assume without loss of generality that $\lambda_{\rm Lang} \leq \frac{1}{2}$,
    so the denominator of this expression is nonzero and
    \[
        \forall \gamma \geq  1, \qquad
        \frac{\e^{- \frac{\lambda_{\rm Lang}}{\gamma} t} - \e^{- \gamma t}}{\gamma - \frac{\lambda_{\rm Lang}}{\gamma}}
        \leq C \e^{-\frac{\lambda_{\rm Lang}}{\gamma} t},
    \]
    which allows to conclude.
    \end{proof}

\begin{proposition}
    \[
        \forall \gamma > 1, \qquad
        \forall t \geq 0, \qquad
        \ip{\e^{t \mathcal L}f}{f} \leq C \left( \gamma^{-1} t \e^{- \frac{t}{\gamma}} + \e^{-\gamma t} \right).
    \]
\end{proposition}
\begin{proof}
In particular, there exists $C > 0$ such that
\begin{equation}
    \label{eq:decay_first_result}
    \forall \gamma > 2, \qquad
    \norm*{ \e^{t \mathcal L} f(q,p) }
    \leq C \left( \norm*{Q} +  \norm*{Q'}\right) \left( \norm*{P} + \norm*{P'} \right)
    \left(\e^{-\gamma t} + \gamma^{-1} \e^{-\gamma^{-1} t}\right).
\end{equation}
Now observe that
\begin{align*}
    \norm{ \int_{0}^{t} \e^{- (t-s) \mathcal L}  x_i(s) \, \d s }
    &\leq \norm{ \int_{0}^{t} \e^{- (t-s) \mathcal L}  \bigl( \Pi_p x_i(s) \bigr) \d s }
    + \norm{ \int_{0}^{t} \e^{- (t-s) \mathcal L}  \bigl(x_i(s) - \Pi_p x_i(s)\bigr)  \d s},
    % &\leq \norm{ \int_{0}^{t} \e^{- (t-s) \mathcal L}  \bigl( \Pi_p x_i(s) \bigr) \d s }
    % + \norm{ \int_{0}^{t} \e^{- (t-s) \mathcal L}  \bigl(x_i(s) - \Pi_p x_i(s)\bigr)  \d s} \\
\end{align*}
and the integrand of the second-term on the right-hand side can be estimated using~\eqref{eq:decay_first_result},
taking into account that
\[
    x_i(t) - \Pi_p x_i(t) = Q^s_i(q) P^s_i(p), \qquad i = 1, 2,
\]
with
is of the
Therefore, employing \eqref{eq:decay_first_result} to the functions $f_1$ and $f_2$,
we can refine our bound on $\norm*{ \e^{t \mathcal L} f(q,p) }$
with

By \cref{lemma:backward_kolmogorov_obs_q},
we have
\[
    \e^{- (t-s) \mathcal L} \bigl(V'(q)\bigr)
    = \e^{- (t-s) \frac{1}{\gamma}\mathcal L_{\rm ov}} V' + R(t),
    % \leq C \e^{- \frac{\lambda}{\gamma} (t-s)} + \frac{C}{\gamma},
\]
where the remainder term is bounded as $\norm{R(t)} \leq \frac{C}{\gamma}$.
Taking the inner product with $p$,
and noting that the constant-in-$p$ part of the integrand vanishes,
we obtain
\[
    \ip{v(t)}{p} = \int_{0}^{t} R(s) \e^{-\gamma s} \, \d s
    \leq \frac{C}{\gamma^2}.
\]
so we deduce
\[
    \norm{v(t)} \leq \int_{0}^{t} \e^{- \frac{\lambda}{\gamma}(t-s)} \e^{- \gamma s} \, \d s + \frac{C}{\gamma^2}.
\]
\end{proof}

% \begin{proof}
%     Let $u(t) = \e^{t \mathcal L} p$ and $v(t) = u(t) - p \e^{-\gamma t}$.
%     The function $v$ satisfies the equation
%     \[
%         \partial_t v = \mathcal L v + V'(q) \, \e^{-\gamma t}, \qquad v(0) = 0.
%     \]
%     Using Duhamel's formula, we have
%     \[
%         v(t) = \int_{0}^{t} \e^{- (t-s) \mathcal L} \bigl(V'(q)\bigr) \e^{-\gamma s} \, \d s
%     \]
%     By \cref{lemma:backward_kolmogorov_obs_q},
%     we have
%     \[
%         \e^{- (t-s) \mathcal L} \bigl(V'(q)\bigr)
%         = \e^{- (t-s) \frac{1}{\gamma}\mathcal L_{\rm ov}} V' + R(t),
%         % \leq C \e^{- \frac{\lambda}{\gamma} (t-s)} + \frac{C}{\gamma},
%     \]
%     where the remainder term is bounded as $\norm{R(t)} \leq \frac{C}{\gamma}$.
%     Taking the inner product with $p$,
%     and noting that the constant-in-$p$ part of the integrand vanishes,
%     we obtain
%     \[
%         \ip{v(t)}{p} = \int_{0}^{t} R(s) \e^{-\gamma s} \, \d s
%         \leq \frac{C}{\gamma^2}.
%     \]
%     so we deduce
%     \[
%         \norm{v(t)} \leq \int_{0}^{t} \e^{- \frac{\lambda}{\gamma}(t-s)} \e^{- \gamma s} \, \d s + \frac{C}{\gamma^2}.
%     \]
% \end{proof}

\begin{lemma}
    \label{lemma:backward_kolmogorov_obs_q}
    Let $\mathcal L_{\rm ovd} = - V'(q) \partial_q + \beta^{-1} \partial_q^2$ and $f \in L^2_0(\nu) \cap C^{\infty}(\torus)$,
    where $\nu$ is given in~\eqref{eq:definition_prob_measures}.
    Let also $\bar f(q, p) = f(q)$ and
    \[
        \widehat u(t) = \e^{t\mathcal L_{\rm ovd}} f, \qquad
        u(t) = \e^{t \gamma\mathcal L} \bar f.
    \]
    Then there exist positive constants $C$ and $\lambda$ independent of $f$ and $\gamma$ such that
    \[
        \forall \gamma \geq 1, \qquad
        \sup_{t \geq \!\!0}
        \norm{u(t)  - \widehat u(t)} \leq
        C \norm{f}_4 \gamma^{-1} \e^{-\lambda t}.
    \]
\end{lemma}
\begin{proof}
    Throughout this proof, $C$ denotes a positive constant that can change from occurrence to occurrence but is independent of $\gamma$ and $f$.
    We recall that there exists a positive constants $\lambda_{\rm Lang}$ such that~\cite{roussel2018spectral,pavliotis2011applied}
    \begin{equation}
        \label{eq:decay_langevin}
        \forall \gamma > 0, \qquad
        \norm{\e^{t \gamma \mathcal L_{\rm Lang}}}[\mathcal B\left(L^2_0(\mu)\right)] \leq C \e^{- \lambda_{\rm Lang} \min\{1,\gamma^2\} t}.
    \end{equation}
    In addition, \cref{lemma:overdamped_langevin_decay_derivatives} implies the existence of $\lambda_{\rm ovd} > 0$ independent of $i$ such that
    \begin{equation}
        \label{eq:decay_ovd}
        \norm{\e^{t \mathcal L_{\rm ovd}}}[\mathcal B\left(H^i_0(\mu)\right)] \leq C \e^{- \lambda_{\rm ovd} t}.
    \end{equation}
    Let
    \(
        \widetilde u(q, p, t) =
        \widehat u(q, t)
        + \gamma^{-1} p \, \partial_q \widehat u(q, t)
        + \gamma^{-2} (p^2 - \beta^{-1}) \partial_q^{2} \widehat u.
    \)
    An explicit calculation gives
    \begin{align*}
        (\partial_t - \gamma \mathcal L) \widetilde u
        &= \gamma^{-1} p \, \partial_t \partial_q \widehat u(q, t) + \gamma^{-2} (p^2 - \beta^{-1}) \partial_t \partial_q^{2} \widehat u
        - \gamma^{-1} p (p^2 - \beta^{-1}) \partial_q^{3} \widehat u + 2 \gamma^{-1} p \, V'(q) \, \partial_q^2 \widehat u.\\
        &= - \gamma^{-1} p \, \partial_q \partial_q^* \partial_q \widehat u(q, t) - \gamma^{-2} (p^2 - \beta^{-1})  \partial_q^{2} \partial_q^* \partial_q \widehat u
        - \gamma^{-1} p (p^2 - \beta^{-1}) \partial_q^{3} \widehat u + 2 \gamma^{-1} p \, V'(q) \, \partial_q^2 \widehat u.
    \end{align*}
    The right-hand side, which we denote by $\gamma^{-1} r(t)$, has values in $L^2_0(\mu)$.
    By the general Leibniz rule gives,
    it is simple to show that
    \[
        \commut{\partial_q^N}{\partial_q^*}
        = \commut{\partial_q^N}{\beta V' - \partial_q}
        = \beta \commut{\partial_q^N}{V'}
        = \beta \sum_{k=1}^{N} {N \choose k} V^{(k+1)} \partial_q^{(N-k)},
    \]
    which can be employed to show that $\norm{r(t)} \leq C \norm{\widehat u(t)}_4$,
    and so $\norm{r(t)} \leq C \e^{-\lambda_{\rm ovd} t} \norm{f}_4$ by~\eqref{eq:decay_ovd}.
    Using the notation $e(t) = u(t) - \widetilde u(t)$,
    we calculate that $e$ satisfies the equation
    \[
        \partial_t e = \gamma \mathcal L e - \gamma^{-1} r, \qquad
        e(0) = \gamma^{-1} p \, f'(q) + \gamma^{-2} (\beta^{-1} - p^2) f''(q).
    \]
    By Duhamel's formula,
    this implies
    \[
        e(t) = \e^{t \gamma \mathcal L} \bigl( e(0) \bigr) + \gamma^{-1} \int_{0}^{t} \e^{(t- s) \gamma \mathcal L} r(s) \, \d s.
    \]
    From~\eqref{eq:decay_langevin} we deduce immediately that
    \begin{align*}
        e(t)
        &\leq C \e^{- \lambda_{\rm Lang} t} \norm{e(0)}
        + C \gamma^{-1} \int_{0}^{t} \e^{- \lambda_{\rm Lang} (t-s)} \e^{-\lambda_{\rm ovd} s} \d s \\
        &\leq C \e^{- \lambda t} \norm{e(0)} + C \norm{f}_4 \gamma^{-1} t \e^{- \lambda t},
    \end{align*}
    for $\lambda = \min(\lambda_{\rm ovd}, \lambda_{\rm Lang})$.
    The result then follows by noticing that $\norm{e_0} \leq C \gamma^{-1} \norm{f}_2$ and
    \[
        \norm{\widetilde u(t) - \widehat u(t)} \leq C \norm{f}_4 \gamma^{-1} \e^{- \lambda_{\rm ovd} t},
    \]
    by \eqref{eq:decay_ovd}.
\end{proof}

The following result shows the exponential convergence of the derivatives of the overdamped Langevin semigroup.
In order to state the result, we define the weighted Sobolev space $H^i(\pi)$ as the subspace of $L^2(\pi)$
of functions whose derivatives up to order $i$ are in $L^2(\pi)$.
The associated norm is given by
\[
    \norm{u}_i^2 = \norm{f}^2 + \norm*{\nabla f}^2 + \dotsb + \norm*{\nabla^i f}^2,
\]
where  $\nabla^j f$ is the tensor containing the $j$-th order derivatives of of $f$and$\norm{\dummy}$ is the norm of~$L^2(\pi)$,
applying to tensors in the usual manner.
We also define $H^{i}_0(\pi) = H^i(\pi) \cap L^2_0(\pi)$,
and we recall that a probability measure $\pi$ is said to satisfy the Poincaré inequality with constant $R$ if
\begin{equation}
    \label{eq:poincare}
    \tag{P$_R$}
    \forall f \in H^1(\pi) \cap L^2_0(\pi), \qquad
    \norm*{f}^2 \leq \frac{1}{2R} \norm{\partial_x f}^2.
\end{equation}

\begin{lemma}
    \label{lemma:overdamped_langevin_decay_derivatives}
    Let $\mathcal X = \real^d$ or $\mathcal X = \torus^d$,
    and let $W: \mathcal X \to \real$ be a smooth potential such that the probability measure
    \[
        \pi(\d x) = \frac{\e^{- \beta W(x)} \d p}{\int_{\real^d} \e^{-\beta W(\widetilde x)} \d \widetilde x}
    \]
    satisfies~\eqref{eq:poincare}.
    Let also $\mathcal L_{\rm ovd}^W = - W'(p) \partial_p + \beta^{-1} \partial_p^2$ denote the generator of overdamped Langevin dynamics in potential~$W$.
    If $f \in H^i_0(\pi) \cap C^{\infty}(\mathcal X)$ for some $i \geq 0$,
    then $\e^{t \mathcal L_{\rm ovd}} f \in H^i_0(\pi)$ and there exists $K = K(i)$ such that
    \[
        \norm*{\e^{t \mathcal L_{\rm ovd}^W} f}_i \leq K \e^{- 2 R t} \norm*{f}_i.
    \]
\end{lemma}
\begin{proof}
    For simplicity, we consider only the case where $\mathcal X = \torus^d$,
    so that we know \emph{a priori} that~$\e^{t \mathcal L_{\rm ovd}^W} f \in H^i_0(\torus^d)$ because
    the state space is compact and $\e^{t \mathcal L_{\rm ovd}^W} f \in C^{\infty}(\torus^d)$ by ellipticity.
    To lighten notations,
    we also confine ourselves to the one-dimensional setting $d = 1$,
    but the proof carries over \emph{mutatis mutandis} to the multi-dimensional case.

    We use the notations $u(t) = \e^{t \mathcal L_{\rm ovd}^W} f$ and
     $\seminorm{h}_j = \norm*{(- \mathcal L_{\rm ovd}^W)^{j/2} h}$ for $j \geq 0$.
    Since $\mathcal L_{\rm ovd}$ commutes with~$(-\mathcal L_{\rm ovd}^W)^{i/2}$,
    it holds that
    \[
        \frac{1}{2} \derivative*{1}{t} \seminorm{u}_j^2 = \ip{\mathcal L_{\rm ovd}^W (-\mathcal L_{\rm ovd})^{j/2} u}{(- \mathcal L_{\rm ovd}^W)^{j/2} u}.
    \]
    Introducing $\partial_x^* = \beta V' - \partial_x$
    and noting that $\mathcal L_{\rm ovd}^W = - \partial_x^* \partial_x$,
    we obtain
    \[
        \frac{1}{2} \derivative*{1}{t} \seminorm{u}_j^2 = - \norm*{\partial_x (-\mathcal L_{\rm ovd}^W)^{j/2} u}.
    \]
    Since $(-\mathcal L_{\rm ovd}^W)^{j/2} u \in L^2_0(\pi)$,
    we can apply Poincar\'e's inequality~\eqref{eq:poincare},
    which gives
    \[
        \frac{1}{2} \derivative*{1}{t} \seminorm{u}_j^2 \leq - 2R \seminorm{u}_j^2,
    \]
    implying the exponential convergence estimate
    \begin{equation}
        \label{eq:exponential_convergence}
        \forall t \geq 0, \qquad
        \seminorm{u(t)}_i \leq \e^{- 2 R t} \seminorm{u(0)}_i.
    \end{equation}
    Applying this estimate with $j = 0$ gives the usual convergence estimate for the norm $\norm{u}$.
    For~$j = 1$, it holds for sufficiently regular $h$ that
    \[
        \seminorm{h}_1 = \norm*{(- \mathcal L_{\rm ovd}^W)^{1/2} h} = \sqrt{\ip{\mathcal L_{\rm ovd}^W h}{h}} = \norm{\partial_x h},
    \]
    so~\eqref{eq:exponential_convergence} implies the exponential convergence of $\norm{\partial_x u}$.
    For $j = 2$, we calculate using the commutator relation $\commut{\partial_x}{\partial_x^*} = \beta V''$ that
    \[
        \seminorm{h}_2^2 = \norm*{- \mathcal L_{\rm ovd}^Wf}^2
        = \ip{\partial_x^* \partial_x h}{\partial_x^* \partial_x h}
        = \norm*{\partial_x^2 h}^2 + \ip{V'' \partial_x h}{\partial_x h}.
    \]
    Therefore~\eqref{eq:exponential_convergence} implies that
    \begin{align*}
        \norm*{\partial_x^2 u}^2
        &\leq \abs{\ip{V'' \partial_x u}{\partial_x u}} + \e^{-4Rt} \bigl( \norm{\partial_x^2 u(0)}^2 + \ip{V'' \partial_x u(0)}{\partial_x u(0)} \bigr) \\
        &\leq \norm*{V''}_{\infty} \norm{\partial_x u}^2 + \e^{-4Rt} \bigl( \norm{\partial_x^2 u(0)}^2 + \norm*{V''}_{\infty} \norm*{\partial_x u(0)}^2 \bigr),
    \end{align*}
    and using the exponential convergence of the first term on the right-hand side,
    which was proved in the previous step,
    allows to conclude that $\norm*{\partial_x^2 u} \leq K \e^{-2 Rt} \norm*{u}^2$ for some appropriate constant $K \geq 1$.
    This procedure can then be repeated in order to deduce the statement.
\end{proof}

\newcommand{\auxnorm}[1]{|\!|\!| #1 |\!|\!|}
\begin{remark}
    An alternative approach for showing~\cref{lemma:overdamped_langevin_decay_derivatives} is
    to define an auxiliary norm
    \[
        \auxnorm{u}_N^2 = \norm*{u}^2 + a_1 \norm*{\partial_x u}^2 + \dotsc + a_N \norm*{\partial_x^N u}^2,
    \]
    with coefficients $a_i = \varepsilon^i$ for some $\varepsilon \in (0, 1)$.
    This norm is equivalent to the weighted Sobolev norm $\norm*{u}_N$,
    and it is possible to show for all $\lambda \in (0, 1)$ that
    \[
        \frac{1}{2}\derivative*{1}{t} \auxnorm{u}_N^2 \leq - 2 R(1 - \lambda) \, \auxnorm{u}_N^2
    \]
    for $\varepsilon$ sufficiently small.
    The reason for the suboptimal rate here is that the term $\norm{\partial_x u}^2$,
    obtained from $\frac{1}{2} \partial_t \norm*{u}^2$,
    needs to control the two terms $\norm{u}^2 + a_1 \norm{\partial_x u}^2$.
\end{remark}

\bibliographystyle{plain}
\bibliography{main}
\end{document}

\begin{proof}
    The general Leibniz rule gives that, for two smooth functions $f(q)$ and $g(q)$,
    \[
        \left( fg \right)^{(N)}
        = \sum_{k=0}^{N} {N \choose k} f^{(k)} g^{(N-k)}.
    \]
    Therefore,
    \begin{equation}
        \label{eq:commutators}
        \commut{\partial_q^N}{f}
        = \sum_{k=1}^{N} {N \choose k} f^{(k)} \partial_q^{(N-k)}.
    \end{equation}
    Let $\partial_q^* = \beta V' - \partial_q$.
    It follows from~\eqref{eq:commutators} that
    \[
        \commut{\partial_q^N}{\partial_q^*}
        = \commut{\partial_q^N}{\beta V' - \partial_q}
        = \beta \commut{\partial_q^N}{V'}
        = \beta \sum_{k=1}^{N} {N \choose k} V^{(k+1)} \partial_q^{(N-k)}.
    \]
    Let $||| u |||_N^2 = \norm*{u}^2 + a_1 \norm*{\partial_q u}^2 + \dotsc + a_N \norm*{\partial_q^N u}^2$,
    with coefficients $a_i = \varepsilon^i$ for some $\varepsilon \in (0, 1)$ that will be defined later.
    Noting that $\mathcal L_{\rm ovd} = - \partial_q^* \partial_q$,
    we obtain
    \begin{align}
        \notag
        \frac{1}{2} \derivative*{1}{t} |||u|||_N^2
        &= - \ip{\partial_q^*\partial_q u}{u} - a_1 \ip{\partial_q \partial_q^* \partial_q u}{\partial_q u} - \dotsb - a_N \ip{\partial_q^N \partial_q^* \partial_q u}{\partial_q^N u} \\
        \notag
        &= - \norm*{u'}^2 - a_1 \norm*{u''}^2 - \dotsb - a_N \norm*{u^{(N+1)}}^2 \\
        \label{eq:derivative_norm}
        &\hspace{5cm} - \beta \sum_{i=1}^{N} a_i \sum_{k=1}^{i} {i \choose k} \ip*{V^{(k+1)} u^{(i-k+1)}}{u^{(i)}}.
    \end{align}
    In order to bound the last term,
    we define
    \[
        M = \frac{\beta}{2} N^N \left( \max_{i \in \{0, 1, \dotsc, N\}} \norm*{V^{(i)}}_{\infty}^2 + 1 \right).
    \]
    Using Young's inequality and the fact that $a_i \geq a_j$ if $i \leq j$, we have
    \begin{align*}
        - \beta \sum_{i=1}^{N} a_i \sum_{k=1}^{i} {i \choose k} \ip*{V^{(k+1)} u^{(i-k+1)}}{u^{(i)}}
        &\leq \frac{\beta}{2} \sum_{i=1}^{N} a_i \sum_{k=1}^{i} {i \choose k} \left( \norm*{V^{(k+1)} u^{(i+1-k)}}^2 + \norm*{u^{(i)}}^2 \right) \\
        &\leq M \sum_{i=1}^{N} a_i \sum_{k=1}^{i} \left( \norm*{u^{(i+1-k)}}^2 + \norm*{u^{(i)}}^2 \right)
        \leq 2 M N \sum_{i=1}^{N} a_i \norm*{u^{(i)}}^2.
    \end{align*}
    Employing this bound in~\eqref{eq:derivative_norm} and choosing $\varepsilon = \frac{\lambda}{2 MN}$ for some $\lambda \in (0, \frac{1}{2})$,
    we obtain
    \begin{align*}
        \notag
        \frac{1}{2} \derivative*{1}{t} |||u|||_N^2
        &\leq - (1 - 2MN a_1) \norm*{\partial_q u}^2 - (a_1 - 2MN a_2) \norm*{\partial_q^2 u}^2 - \dotsb - (a_{N-1} - 2MN a_{N}) \norm*{\partial_q^N u}^2 \\
        &\leq - \left( 1 - \lambda \right) \norm{\partial_q u}^2 - \left( 1 - \lambda \right) \varepsilon \norm*{\partial_q^2 u}^2 - \dotsb - \left( 1 - \lambda \right) \varepsilon^{N-1} \norm*{\partial_q^N u}^2 \\
        &\leq - 2 \alpha R \norm{u}^2 - (1 - \alpha)(1 - \lambda) \norm{\partial_q u}^2 - \varepsilon^2 \norm*{\partial_q^2 u}^2 - \dotsb - \varepsilon^N \norm*{\partial_q^N u}^2 \qquad \forall \alpha \in (0, 1).
    \end{align*}
    Choosing $\alpha$ such that $(1 - \alpha)(1 - \lambda) = \varepsilon$,
    we obtain $\frac{1}{2} \partial_t |||u|||_N^2 \leq - 2 R (1 - \lambda) |||u|||^2$,
    which leads by Gr\"onwall's inequality to the exponential convergence estimate
    \[
        \forall t \geq 0, \qquad |||u(t)|||_N^2 \leq \e^{-2 R (1 - \lambda) t} |||u(0)|||_N^2.
    \]
    Using the equivalence of between the norms $\norm{\dummy}_N$ and $|||\dummy|||_N$ allows to conclude.
    \textcolor{red}{Not sharp!}
\end{proof}
